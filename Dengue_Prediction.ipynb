{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuAHR23xBDCm",
        "outputId": "8cd29ea7-7d30-4ba9-f662-52cd288ec98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "id": "gaeR6DpPBJm6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Dengue Dataset/dataset.csv'  #paste korba file path\n",
        "data = pd.read_csv(file_path)  #ei function ta direct link theke data niye ney dataframe e\n"
      ],
      "metadata": {
        "id": "bV9Qv8rvBNKS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(numeric_only=True), inplace=True)  #missing value fill kore mean koray\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['District'] = label_encoder.fit_transform(data['District'])   #district er names encode korbe\n",
        "\n",
        "X = data.drop(columns=['January', 'February', 'March', 'April', 'May',\n",
        "                       'June', 'July', 'August', 'September', 'October',\n",
        "                       'November', 'December'])    #features select korlam output drop dia\n",
        "Y = data[['January', 'February', 'March', 'April', 'May',\n",
        "          'June', 'July', 'August', 'September', 'October',\n",
        "          'November', 'December']]   #output select korlam\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)     #0.2 means 20% for test data\n"
      ],
      "metadata": {
        "id": "U-ZsrzVDBSXv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Support Vector Regressor\": SVR(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=10, random_state=42),\n",
        "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=10, random_state=42),\n",
        "    \"XGBoost Regressor\": XGBRegressor(n_estimators=10, random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "uljst-HwBWtN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "\n",
        "for month in Y.columns:\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, Y_train[month])\n",
        "        Y_pred = model.predict(X_test)\n",
        "\n",
        "        mae = mean_absolute_error(Y_test[month], Y_pred)\n",
        "        mse = mean_squared_error(Y_test[month], Y_pred)\n",
        "        r2 = r2_score(Y_test[month], Y_pred)\n",
        "\n",
        "        results.append({\n",
        "            \"Month\": month,\n",
        "            \"Model\": name,\n",
        "            \"MAE\": mae,\n",
        "            \"MSE\": mse,\n",
        "            \"R-squared\": r2\n",
        "        })\n"
      ],
      "metadata": {
        "id": "iD79vj2uBdl-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(\"Model Performance Results:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "BWZ1aUkgBrSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad11867-301c-499e-fcd1-60e4e1960dc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Results:\n",
            "        Month                        Model          MAE           MSE  \\\n",
            "0     January            Linear Regression    12.301158  1.076428e+03   \n",
            "1     January     Support Vector Regressor     7.804389  1.088472e+03   \n",
            "2     January      Random Forest Regressor    12.076120  1.443932e+03   \n",
            "3     January  Gradient Boosting Regressor    12.052738  1.568340e+03   \n",
            "4     January            XGBoost Regressor    10.403070  1.117107e+03   \n",
            "5    February            Linear Regression    11.380461  4.775748e+02   \n",
            "6    February     Support Vector Regressor     6.000619  4.468382e+02   \n",
            "7    February      Random Forest Regressor     7.085264  2.805538e+02   \n",
            "8    February  Gradient Boosting Regressor     8.192282  4.351816e+02   \n",
            "9    February            XGBoost Regressor     6.536248  4.125640e+02   \n",
            "10      March            Linear Regression    13.261986  6.506695e+02   \n",
            "11      March     Support Vector Regressor     6.010194  5.807261e+02   \n",
            "12      March      Random Forest Regressor     7.651282  3.334498e+02   \n",
            "13      March  Gradient Boosting Regressor     8.993140  5.365659e+02   \n",
            "14      March            XGBoost Regressor     7.169373  4.357109e+02   \n",
            "15      April            Linear Regression    13.626228  6.713861e+02   \n",
            "16      April     Support Vector Regressor     6.338709  5.915434e+02   \n",
            "17      April      Random Forest Regressor     8.844026  5.572971e+02   \n",
            "18      April  Gradient Boosting Regressor     9.454529  6.062508e+02   \n",
            "19      April            XGBoost Regressor     7.210815  4.508725e+02   \n",
            "20        May            Linear Regression    26.072262  1.016162e+04   \n",
            "21        May     Support Vector Regressor    18.065587  1.031305e+04   \n",
            "22        May      Random Forest Regressor    20.887281  9.845412e+03   \n",
            "23        May  Gradient Boosting Regressor    21.445055  1.022105e+04   \n",
            "24        May            XGBoost Regressor    23.675277  9.925077e+03   \n",
            "25       June            Linear Regression    85.315612  2.873994e+05   \n",
            "26       June     Support Vector Regressor    76.799015  2.909854e+05   \n",
            "27       June      Random Forest Regressor    82.014440  2.903269e+05   \n",
            "28       June  Gradient Boosting Regressor    84.908028  2.907077e+05   \n",
            "29       June            XGBoost Regressor    84.017169  2.946821e+05   \n",
            "30       July            Linear Regression   415.856112  7.022113e+06   \n",
            "31       July     Support Vector Regressor   422.372183  7.207942e+06   \n",
            "32       July      Random Forest Regressor   405.663231  6.968594e+06   \n",
            "33       July  Gradient Boosting Regressor   425.151193  7.090918e+06   \n",
            "34       July            XGBoost Regressor   408.060678  7.039126e+06   \n",
            "35     August            Linear Regression  1588.030787  1.860950e+07   \n",
            "36     August     Support Vector Regressor  1780.364813  2.278255e+07   \n",
            "37     August      Random Forest Regressor  1414.544156  1.628257e+07   \n",
            "38     August  Gradient Boosting Regressor  1397.112905  1.573313e+07   \n",
            "39     August            XGBoost Regressor  1358.116405  1.550983e+07   \n",
            "40  September            Linear Regression   634.751211  8.208214e+06   \n",
            "41  September     Support Vector Regressor   589.523433  8.976235e+06   \n",
            "42  September      Random Forest Regressor   741.774026  8.732655e+06   \n",
            "43  September  Gradient Boosting Regressor   675.687703  8.922748e+06   \n",
            "44  September            XGBoost Regressor   612.014407  8.244216e+06   \n",
            "45    October            Linear Regression   565.236105  3.320661e+06   \n",
            "46    October     Support Vector Regressor   438.893829  3.811488e+06   \n",
            "47    October      Random Forest Regressor   654.572727  4.088319e+06   \n",
            "48    October  Gradient Boosting Regressor   579.835736  4.349646e+06   \n",
            "49    October            XGBoost Regressor   487.285482  3.747070e+06   \n",
            "50   November            Linear Regression   324.813838  1.058912e+06   \n",
            "51   November     Support Vector Regressor   270.410315  1.230220e+06   \n",
            "52   November      Random Forest Regressor   299.017110  1.074544e+06   \n",
            "53   November  Gradient Boosting Regressor   297.023852  1.110674e+06   \n",
            "54   November            XGBoost Regressor   337.530277  1.631035e+06   \n",
            "55   December            Linear Regression    98.312694  7.085913e+04   \n",
            "56   December     Support Vector Regressor    81.601534  8.209380e+04   \n",
            "57   December      Random Forest Regressor   111.310390  7.799552e+04   \n",
            "58   December  Gradient Boosting Regressor   104.847837  8.804366e+04   \n",
            "59   December            XGBoost Regressor   112.215823  1.355185e+05   \n",
            "\n",
            "    R-squared  \n",
            "0   -0.027781  \n",
            "1   -0.039281  \n",
            "2   -0.378676  \n",
            "3   -0.497462  \n",
            "4   -0.066622  \n",
            "5   -0.137517  \n",
            "6   -0.064306  \n",
            "7    0.331760  \n",
            "8   -0.036542  \n",
            "9    0.017330  \n",
            "10  -0.172634  \n",
            "11  -0.046582  \n",
            "12   0.399058  \n",
            "13   0.033003  \n",
            "14   0.214764  \n",
            "15  -0.193384  \n",
            "16  -0.051464  \n",
            "17   0.009409  \n",
            "18  -0.077606  \n",
            "19   0.198578  \n",
            "20  -0.017192  \n",
            "21  -0.032350  \n",
            "22   0.014461  \n",
            "23  -0.023141  \n",
            "24   0.006486  \n",
            "25  -0.006095  \n",
            "26  -0.018648  \n",
            "27  -0.016343  \n",
            "28  -0.017676  \n",
            "29  -0.031589  \n",
            "30   0.003243  \n",
            "31  -0.023135  \n",
            "32   0.010839  \n",
            "33  -0.006524  \n",
            "34   0.000828  \n",
            "35   0.054678  \n",
            "36  -0.157303  \n",
            "37   0.172881  \n",
            "38   0.200791  \n",
            "39   0.212135  \n",
            "40   0.053628  \n",
            "41  -0.034921  \n",
            "42  -0.006837  \n",
            "43  -0.028754  \n",
            "44   0.049477  \n",
            "45   0.090917  \n",
            "46  -0.043454  \n",
            "47  -0.119241  \n",
            "48  -0.190783  \n",
            "49  -0.025819  \n",
            "50   0.100358  \n",
            "51  -0.045183  \n",
            "52   0.087077  \n",
            "53   0.056382  \n",
            "54  -0.385712  \n",
            "55   0.097148  \n",
            "56  -0.045998  \n",
            "57   0.006220  \n",
            "58  -0.121809  \n",
            "59  -0.726710  \n"
          ]
        }
      ]
    }
  ]
}