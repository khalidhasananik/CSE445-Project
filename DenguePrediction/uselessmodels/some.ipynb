{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All combinations evaluated:\n",
      "      Strategy  Test_Size  Random_State           MSE        R2\n",
      "8       median       0.20             0  6.651170e+06  0.192913\n",
      "12        mode       0.20             0  6.752299e+06  0.181207\n",
      "0   constant_0       0.20             0  8.273964e+06 -0.003312\n",
      "16       ffill       0.20             0  8.464212e+06 -0.006986\n",
      "4         mean       0.20             0  8.791686e+06 -0.046018\n",
      "20       bfill       0.20             0  1.321828e+07 -0.571339\n",
      "22       bfill       0.25             0  2.075792e+07 -0.011036\n",
      "10      median       0.25             0  2.091350e+07 -0.026661\n",
      "6         mean       0.25             0  2.094780e+07 -0.022277\n",
      "14        mode       0.25             0  2.105279e+07 -0.033108\n",
      "18       ffill       0.25             0  2.113101e+07 -0.032163\n",
      "2   constant_0       0.25             0  2.357735e+07 -0.156994\n",
      "23       bfill       0.25            42  6.629017e+07  0.447642\n",
      "15        mode       0.25            42  6.745578e+07  0.437678\n",
      "7         mean       0.25            42  7.327250e+07  0.389669\n",
      "3   constant_0       0.25            42  7.395507e+07  0.383499\n",
      "19       ffill       0.25            42  7.420534e+07  0.380816\n",
      "11      median       0.25            42  8.417686e+07  0.298232\n",
      "13        mode       0.20            42  1.320103e+08  0.105250\n",
      "17       ffill       0.20            42  1.365262e+08  0.073838\n",
      "9       median       0.20            42  1.395809e+08  0.053863\n",
      "5         mean       0.20            42  1.398688e+08  0.052499\n",
      "21       bfill       0.20            42  1.408996e+08  0.045393\n",
      "1   constant_0       0.20            42  1.414450e+08  0.041302\n",
      "\n",
      "Best combination:\n",
      "{'Strategy': 'median', 'Test_Size': 0.2, 'Random_State': 0, 'MSE': 6651169.918828467, 'R2': 0.19291319463698842}\n",
      "\n",
      "Final Model Evaluation with Bootstrapping:\n",
      "Mean Squared Error (MSE): 10162776.835608887\n",
      "R-squared (R²): -0.2332030590061258\n",
      "\n",
      "Final Model Evaluation:\n",
      "Mean Squared Error (MSE): 6651169.918828467\n",
      "R-squared (R²): 0.19291319463698842\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "dengue_data = pd.read_csv('dataset/dataset.csv')\n",
    "\n",
    "# Define missing value handling strategies\n",
    "missing_value_strategies = {\n",
    "    'constant_0': SimpleImputer(strategy='constant', fill_value=0),\n",
    "    'mean': SimpleImputer(strategy='mean'),\n",
    "    'median': SimpleImputer(strategy='median'),\n",
    "    'mode': SimpleImputer(strategy='most_frequent'),\n",
    "    'mode': SimpleImputer(strategy='most_frequent'),\n",
    "    'ffill': 'ffill',\n",
    "    'bfill': 'bfill'\n",
    "}\n",
    "\n",
    "# Test sizes and random states\n",
    "test_sizes = [0.2, 0.25]\n",
    "random_states = [0, 42]\n",
    "\n",
    "# To track the best combination\n",
    "best_combination = None\n",
    "best_mse = np.inf\n",
    "best_r2 = -np.inf\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Iterate through all combinations of strategies, test sizes, and random states\n",
    "for strategy_name, strategy in missing_value_strategies.items():\n",
    "    # Prepare a copy of the dataset\n",
    "    data = dengue_data.copy()\n",
    "\n",
    "    # Handle missing values\n",
    "    if strategy_name in ['ffill', 'bfill']:\n",
    "        if strategy_name == 'ffill':\n",
    "            data.ffill(inplace=True)\n",
    "        else:\n",
    "            data.bfill(inplace=True)\n",
    "        # data.fillna(method=strategy_name, inplace=True)\n",
    "    else:\n",
    "        data.iloc[:, 2:] = strategy.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "    # Encode categorical data\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['District'] = label_encoder.fit_transform(data['District'])\n",
    "\n",
    "    # Create the target variable for July to November\n",
    "    data['Target_July_to_November'] = data[['July', 'August', 'September', 'October', 'November']].sum(axis=1)\n",
    "\n",
    "    # Create lag features\n",
    "    data['Previous_Year_July_to_November'] = data.groupby('District')[\n",
    "        ['July', 'August', 'September', 'October', 'November']\n",
    "    ].shift(1).sum(axis=1).fillna(0)\n",
    "\n",
    "    # Define features and target\n",
    "    features = data.drop(columns=[\n",
    "        'January', 'February', 'March', 'April', 'May', 'June', 'December',\n",
    "        'July', 'August', 'September', 'October', 'November', 'Target_July_to_November'\n",
    "    ])\n",
    "    features['Previous_Year_July_to_November'] = data['Previous_Year_July_to_November']\n",
    "    target = data['Target_July_to_November']\n",
    "\n",
    "    # Handle any remaining missing values\n",
    "    features = features.fillna(0)\n",
    "    target = target.fillna(0)\n",
    "\n",
    "    # Try different train-test splits\n",
    "    for test_size in test_sizes:\n",
    "        for random_state in random_states:\n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                features, target, test_size=test_size, random_state=random_state\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model = AdaBoostRegressor(n_estimators=100, random_state=random_state)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Save results\n",
    "            results.append({\n",
    "                'Strategy': strategy_name,\n",
    "                'Test_Size': test_size,\n",
    "                'Random_State': random_state,\n",
    "                'MSE': mse,\n",
    "                'R2': r2\n",
    "            })\n",
    "\n",
    "            # Update best combination\n",
    "            if mse < best_mse or (mse == best_mse and r2 > best_r2):\n",
    "                best_combination = {\n",
    "                    'Strategy': strategy_name,\n",
    "                    'Test_Size': test_size,\n",
    "                    'Random_State': random_state,\n",
    "                    'MSE': mse,\n",
    "                    'R2': r2\n",
    "                }\n",
    "                best_mse = mse\n",
    "                best_r2 = r2\n",
    "\n",
    "# Results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by='MSE', inplace=True)\n",
    "\n",
    "# Display all combinations\n",
    "print(\"All combinations evaluated:\")\n",
    "print(results_df)\n",
    "\n",
    "# Display the best combination\n",
    "print(\"\\nBest combination:\")\n",
    "print(best_combination)\n",
    "\n",
    "# Use the best combination to train the final model\n",
    "data = dengue_data.copy()\n",
    "\n",
    "# Apply the best strategy\n",
    "strategy_name = best_combination['Strategy']\n",
    "if strategy_name in ['forward_fill', 'backward_fill']:\n",
    "    if strategy_name == 'forward_fill':\n",
    "        data.ffill(inplace=True)\n",
    "    else:\n",
    "        data.bfill(inplace=True)\n",
    "    # data.fillna(method=strategy_name, inplace=True)\n",
    "else:\n",
    "    imputer = missing_value_strategies[strategy_name]\n",
    "    data.iloc[:, 2:] = imputer.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "# Encode categorical data\n",
    "data['District'] = label_encoder.fit_transform(data['District'])\n",
    "data['Target_July_to_November'] = data[['July', 'August', 'September', 'October', 'November']].sum(axis=1)\n",
    "data['Previous_Year_July_to_November'] = data.groupby('District')[\n",
    "    ['July', 'August', 'September', 'October', 'November']\n",
    "].shift(1).sum(axis=1).fillna(0)\n",
    "\n",
    "features = data.drop(columns=[\n",
    "    'January', 'February', 'March', 'April', 'May', 'June', 'December',\n",
    "    'July', 'August', 'September', 'October', 'November', 'Target_July_to_November'\n",
    "])\n",
    "features['Previous_Year_July_to_November'] = data['Previous_Year_July_to_November']\n",
    "target = data['Target_July_to_November']\n",
    "\n",
    "# print(dengue_data)\n",
    "\n",
    "# Handle remaining missing values\n",
    "# features = features.fillna(0)\n",
    "# target = target.fillna(0)\n",
    "\n",
    "# Split data using the best parameters\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=best_combination['Test_Size'], random_state=best_combination['Random_State']\n",
    ")\n",
    "\n",
    "# Perform bootstrapping to increase sample size\n",
    "# n_samples = X_train.shape[0] * 5 # 5 times the original sample size\n",
    "n_samples = 1000\n",
    "bootstrapped_indices = np.random.choice(np.arange(X_train.shape[0]), size=n_samples, replace=True)\n",
    "X_train_bootstrapped = X_train.iloc[bootstrapped_indices].values\n",
    "y_train_bootstrapped = y_train.iloc[bootstrapped_indices].values\n",
    "\n",
    "# Alternative bootstrapping using resample from sklearn.utils\n",
    "# Resample the training data\n",
    "X_train_bootstrapped, y_train_bootstrapped = resample(X_train, y_train, n_samples=n_samples, random_state=best_combination['Random_State'])\n",
    "\n",
    "# Perform Cross-Validation\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "# model = AdaBoostRegressor(n_estimators=100, random_state=best_combination['Random_State'])\n",
    "# cv_scores = cross_val_score(model, X_train_bootstrapped, y_train_bootstrapped, cv=5, scoring='neg_mean_squared_error')\n",
    "# cv_mse = -cv_scores.mean()\n",
    "\n",
    "# print(\"\\nCross-Validation Mean Squared Error (MSE):\", cv_mse)\n",
    "\n",
    "# Train the final model with Bootstrapped AdaBoostRegressor\n",
    "final_model = AdaBoostRegressor(n_estimators=100, random_state=best_combination['Random_State'])\n",
    "final_model.fit(X_train_bootstrapped, y_train_bootstrapped)\n",
    "\n",
    "# Make final predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the final model\n",
    "final_mse = mean_squared_error(y_test, y_pred)\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation with Bootstrapping:\")\n",
    "print(f\"Mean Squared Error (MSE): {final_mse}\")\n",
    "print(f\"R-squared (R²): {final_r2}\")\n",
    "\n",
    "\n",
    "\n",
    "# Train the final model with AdaBoostRegressor\n",
    "final_model = AdaBoostRegressor(n_estimators=100, random_state=best_combination['Random_State'])\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make final predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the final model\n",
    "final_mse = mean_squared_error(y_test, y_pred)\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {final_mse}\")\n",
    "print(f\"R-squared (R²): {final_r2}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the final model with RandomForestRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# final_model = RandomForestRegressor(n_estimators=100, random_state=best_combination['Random_State'])\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the final model with GradientBoostingRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# final_model = GradientBoostingRegressor(n_estimators=100, random_state=best_combination['Random_State'])\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# hyperparameter tuning for XGBRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from xgboost import XGBRegressor\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 150, 200],\n",
    "#     'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "#     'max_depth': [3, 4, 5, 6, 7],\n",
    "#     'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#     'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "#     'min_child_weight': [1, 2, 3, 4]\n",
    "# }\n",
    "# xgb = XGBRegressor()\n",
    "# grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(grid_search.best_params_)\n",
    "# final_model = grid_search.best_estimator_\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make final predictions\n",
    "# y_pred = final_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the final model\n",
    "# final_mse = mean_squared_error(y_test, y_pred)\n",
    "# final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(\"\\nFinal Model Evaluation:\")\n",
    "# print(f\"Mean Squared Error (MSE): {final_mse}\")\n",
    "# print(f\"R-squared (R²): {final_r2}\")\n",
    "\n",
    "# # Visualize predictions vs actual cases\n",
    "# district_predictions = pd.DataFrame({\n",
    "#     'District': X_test['District'],\n",
    "#     'Predicted_Cases': y_pred,\n",
    "#     'Actual_Cases': y_test.values\n",
    "# }).reset_index(drop=True)\n",
    "\n",
    "# # Decode district labels back to their original names\n",
    "# district_predictions['District'] = label_encoder.inverse_transform(district_predictions['District'])\n",
    "\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# district_predictions.sort_values('Actual_Cases').plot(\n",
    "#     kind='bar', x='District', y=['Predicted_Cases', 'Actual_Cases'], figsize=(14, 8)\n",
    "# )\n",
    "# plt.title('Predicted vs Actual Dengue Cases (July to November) by District', fontsize=16)\n",
    "# plt.xlabel('District', fontsize=12)\n",
    "# plt.ylabel('Number of Cases (July to November)', fontsize=12)\n",
    "# plt.legend(['Predicted Cases', 'Actual Cases'], fontsize=12)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
